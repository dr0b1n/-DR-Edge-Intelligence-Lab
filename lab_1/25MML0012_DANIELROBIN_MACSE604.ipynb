{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9de81a-fcfd-4847-a4d4-39329a3ce721",
   "metadata": {},
   "source": [
    "# RAW cars dataset (uncleaned)\n",
    "\n",
    "- This repository contains 225 RAW images of scenes containing cars.\n",
    "\n",
    "## RAW_converted (the folder that contains the uncleaned images we're using)\n",
    "\n",
    "- The original RAW images have been scaled to [0, 255] from their original scale of [0, 1023] and converted to the lossless PNG image format. This reduces their size and make circulation feasible.\n",
    "\n",
    "- ### For the sake of simplicity, I'm only reading 5 images for processing\n",
    "\n",
    "- ### We can see that the 5 images I selected have different shapes\n",
    "\n",
    "## This is just a simple program to resize an image to (150, 150), the final output images may be stretched or compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75ae0101-d234-45df-bd18-66e6249644ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download and resize of 5 images (.png format)...\n",
      "\n",
      "Processing 1.png...\n",
      "  Original size (Uncleaned): (3480, 4640)\n",
      "  Resized size (Cleaned): (150, 150)\n",
      "\n",
      "Processing 2.png...\n",
      "  Original size (Uncleaned): (3480, 4640)\n",
      "  Resized size (Cleaned): (150, 150)\n",
      "\n",
      "Processing 3.png...\n",
      "  Original size (Uncleaned): (4640, 3480)\n",
      "  Resized size (Cleaned): (150, 150)\n",
      "\n",
      "Processing 4.png...\n",
      "  Original size (Uncleaned): (4640, 3480)\n",
      "  Resized size (Cleaned): (150, 150)\n",
      "\n",
      "Processing 5.png...\n",
      "  Original size (Uncleaned): (4640, 3480)\n",
      "  Resized size (Cleaned): (150, 150)\n",
      "\n",
      "--- Final Dataset Summary ---\n",
      "Successfully loaded and resized 5 images in 2433.78 seconds.\n",
      "Final Cleaned Dataset Shape (N, H, W, C): (5, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "# Base URL for the raw image files (RAW_converted directory)\n",
    "BASE_RAW_URL = \"https://raw.githubusercontent.com/EkdeepSLubana/raw_dataset/master/RAW_converted/\"\n",
    "# Define the range of images: 1.png to 5.png\n",
    "IMAGE_IDS = range(1, 6) \n",
    "\n",
    "# The uniform size we want for the \"Cleaned\" dataset\n",
    "TARGET_SIZE = (150, 150) \n",
    "cleaned_dataset = []\n",
    "successful_loads = 0\n",
    "\n",
    "print(f\"Starting download and resize of {len(IMAGE_IDS)} images (.png format)...\")\n",
    "\n",
    "# --- Iterate through URLs, Load, and Resize ---\n",
    "for img_id in IMAGE_IDS:\n",
    "    file_name = f\"{img_id}.png\"\n",
    "    full_url = BASE_RAW_URL + file_name\n",
    "    \n",
    "    # --- OUTPUT FOR ALL 5 IMAGES ---\n",
    "    print(f\"\\nProcessing {file_name}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(full_url, stream=True, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        image_bytes = io.BytesIO(response.content)\n",
    "\n",
    "        # Convert to 'RGB' to ensure 3 channels\n",
    "        img = Image.open(image_bytes).convert('RGB') \n",
    "        \n",
    "        # --- OUTPUT FOR ALL 5 IMAGES ---\n",
    "        print(f\"  Original size (Uncleaned): {img.size}\") \n",
    "        \n",
    "        resized_img = img.resize(TARGET_SIZE)\n",
    "\n",
    "        image_array = np.array(resized_img)\n",
    "        cleaned_dataset.append(image_array)\n",
    "        successful_loads += 1\n",
    "        \n",
    "        # --- OUTPUT FOR ALL 5 IMAGES ---\n",
    "        print(f\"  Resized size (Cleaned): {resized_img.size}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Skipping {file_name}: Download error: {e}\")\n",
    "    except IOError:\n",
    "        print(f\"Skipping {file_name}: Failed to open or process image.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {file_name}: An unexpected error occurred: {e}\")\n",
    "\n",
    "# ... (Final Summary) ...\n",
    "end_time = time.time()\n",
    "if cleaned_dataset:\n",
    "    final_data = np.stack(cleaned_dataset)\n",
    "    print(\"\\n--- Final Dataset Summary ---\")\n",
    "    print(f\"Successfully loaded and resized {successful_loads} images in {end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"Final Cleaned Dataset Shape (N, H, W, C): {final_data.shape}\")\n",
    "else:\n",
    "    print(\"\\n--- Final Dataset Summary ---\")\n",
    "    print(\"No images were successfully loaded due to network issues. The final shape explanation assumes successful execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0959c-eb23-40a1-a663-425553f24411",
   "metadata": {},
   "source": [
    "- N - This is the batch size, representing the total count of images that were successfully loaded and stacked (1.png through 10.png).\n",
    "- H - The fixed vertical dimension (height) of every single image, as enforced by the TARGET_SIZE = (150, 150) parameter.\n",
    "- W - The fixed horizontal dimension (width) of every single image, also enforced by the TARGET_SIZE parameter.\n",
    "- C - The number of color channels. PNG images typically store color data as RGB (Red, Green, Blue), which requires 3 channels.\n",
    "\n",
    "### All (selected) images have been resized to (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db280da-6765-4b3d-bc31-d658c62be351",
   "metadata": {},
   "source": [
    "# POSSIBLE ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69fcc3d-bf3d-4e73-b368-94097a6981fe",
   "metadata": {},
   "source": [
    "## Incorrect File Extension (Should be .png, but requesting .jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80412ff5-fc18-49ba-aa7b-ab5573a45541",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://raw.githubusercontent.com/EkdeepSLubana/raw_dataset/master/RAW_converted/1.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m url_error_a \u001b[38;5;241m=\u001b[39m BASE_RAW_URL \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m response_a \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url_error_a)\n\u001b[1;32m----> 3\u001b[0m response_a\u001b[38;5;241m.\u001b[39mraise_for_status() \u001b[38;5;66;03m# This will raise an HTTPError (404 Not Found)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile A loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mainpro\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/EkdeepSLubana/raw_dataset/master/RAW_converted/1.jpg"
     ]
    }
   ],
   "source": [
    "url_error_a = BASE_RAW_URL + \"1.jpg\"\n",
    "response_a = requests.get(url_error_a)\n",
    "response_a.raise_for_status() # This will raise an HTTPError (404 Not Found)\n",
    "print(\"File A loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715ef7a-0b12-43eb-921a-8ecebbf1fa71",
   "metadata": {},
   "source": [
    "## Attempting to read a non-image file (e.g., README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77f799b4-9833-4529-80bc-de8800e1052d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x0000025D1C25B060>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m file_bytes_c \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(response_c\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This will raise a PIL.UnidentifiedImageError or similar IOError\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m img_c \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(file_bytes_c) \n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage C opened successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mainpro\\Lib\\site-packages\\PIL\\Image.py:3498\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3496\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3497\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3498\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x0000025D1C25B060>"
     ]
    }
   ],
   "source": [
    "# NOTE: Need to adjust BASE_RAW_URL to access the root repo directory\n",
    "base_url_for_readme = \"https://raw.githubusercontent.com/EkdeepSLubana/raw_dataset/master/\"\n",
    "url_error_c = base_url_for_readme + \"README.md\"\n",
    "\n",
    "response_c = requests.get(url_error_c)\n",
    "file_bytes_c = io.BytesIO(response_c.content)\n",
    "\n",
    "# This will raise a PIL.UnidentifiedImageError or similar IOError\n",
    "img_c = Image.open(file_bytes_c) \n",
    "print(\"Image C opened successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311221a-c725-47e8-bf43-93c284a7cc99",
   "metadata": {},
   "source": [
    "## Invalid Resize Target (Needs tuple, giving an int)\n",
    "- Here we try using 150 for shape instead of (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "918cd403-b825-48f3-bc74-23467b5d2bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error D: argument 1 must be 2-item sequence, not int\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'img' is a successfully loaded image object\n",
    "if 'img' in locals():\n",
    "    try:\n",
    "        # This will raise a TypeError because 150 is not a tuple\n",
    "        resized_img_d = img.resize(150) \n",
    "        print(\"Resize D successful.\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error D: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d7909-a402-475a-aa40-00e898b135f1",
   "metadata": {},
   "source": [
    "## Attempting to Stack Unresized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bcc67a0-eb97-4a4e-80b4-3333330fc6bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m uncleaned_list \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(img_1), np\u001b[38;5;241m.\u001b[39marray(img_5)]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# This will raise a ValueError because the arrays (images) have different shapes\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m np\u001b[38;5;241m.\u001b[39mstack(uncleaned_list) \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStack E successful.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mainpro\\Lib\\site-packages\\numpy\\_core\\shape_base.py:457\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    455\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    459\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    460\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# Load two images (1.png and 5.png) of different original sizes:\n",
    "img_1_url = BASE_RAW_URL + \"1.png\"\n",
    "img_5_url = BASE_RAW_URL + \"5.png\"\n",
    "\n",
    "img_1 = Image.open(io.BytesIO(requests.get(img_1_url).content)).convert('RGB')\n",
    "img_5 = Image.open(io.BytesIO(requests.get(img_5_url).content)).convert('RGB')\n",
    "\n",
    "uncleaned_list = [np.array(img_1), np.array(img_5)]\n",
    "\n",
    "# This will raise a ValueError because the arrays (images) have different shapes\n",
    "np.stack(uncleaned_list) \n",
    "print(\"Stack E successful.\") # This line will not be reached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8f079-4aa3-4cf6-ba12-806b40ef2b8f",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bc0cf",
   "metadata": {},
   "source": [
    "### messy-vs-clean-room dataset (uncleaned)\n",
    "\n",
    "this code doesn't read any actual images, so nevermind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b402526",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "github_url = \"https://github.com/GuanqiaoDing/messy-room-classifier/blob/master/data/room_dataset.npy\"\n",
    "\n",
    "# Convert the GitHub web URL to the raw file URL\n",
    "raw_url = github_url.replace(\"blob\", \"raw\")\n",
    "\n",
    "# Use the requests library to fetch the content from the raw URL\n",
    "response = requests.get(raw_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    file_bytes = io.BytesIO(response.content)\n",
    "    \n",
    "    # Load the NumPy array from the bytes data\n",
    "    data = np.load(file_bytes, allow_pickle=True)\n",
    "    \n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "    print(f\"First few entries: {data[:2]}\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c67371",
   "metadata": {},
   "source": [
    "### importing the MNIST dataset (cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d414bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n",
      "Dataset successfully loaded.\n",
      "x train shape: (60000, 28, 28)\n",
      "y train shape: (60000,)\n",
      "x test shape: (10000, 28, 28)\n",
      "y test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "url=\"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\"\n",
    "local_path = \"mnist.npz\"\n",
    "\n",
    "try:\n",
    "    # 1. Download the file from the URL\n",
    "    urllib.request.urlretrieve(url, local_path)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    # 2. Load the data using numpy\n",
    "    data = np.load(local_path, allow_pickle=True)\n",
    "\n",
    "    # 3. Extract the data arrays from the loaded object\n",
    "    xtrain = data['x_train']\n",
    "    ytrain = data['y_train']\n",
    "    xtest = data['x_test']\n",
    "    ytest = data['y_test']\n",
    "    \n",
    "    print(\"Dataset successfully loaded.\")\n",
    "\n",
    "    # 4. Display shapes to verify\n",
    "    print(f\"x train shape: {xtrain.shape}\")\n",
    "    print(f\"y train shape: {ytrain.shape}\")\n",
    "    print(f\"x test shape: {xtest.shape}\")\n",
    "    print(f\"y test labels shape: {ytest.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05223387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
